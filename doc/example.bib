@misc{Pixabay:ImgStandards,
  author = {Steinberger, Simon},
  title = {{Photography Training and Image Quality Standards}},
  year = {2012},
  url= {https://pixabay.com/en/blog/posts/photography-training-and-image-quality-standards-22/},
  urldate = {2017-10-24}
}

@misc{Pixabay:Tagging,
 author = {Steinberger, Simon},
 title = {{Tagging Tutorial for Pixabay Images}},
 year = {2014},
 url= {https://pixabay.com/en/blog/posts/tagging-tutorial-for-pixabay-images-54/},
 urldate = {2017-10-24}
}

@misc{Pixabay:API,
 author = {Steinberger, Simon},
 title = {{Pixabay API}},
 year = {2014},
 url= {https://pixabay.com/api/docs/},
 urldate = {2017-10-28}
}

@book{Herrera:2016,
 author = {Francisco Herrera and Francisco Charte and Antonio J. Rivera and María J. del Jesus},
 Title = {Multilabel Classification},
 Year = {2016},
 Publisher = {Springer International Publishing},
 Pages = {17--31}
}

@article{SOKOLOVA2009427,
title = "A systematic analysis of performance measures for classification tasks",
journal = "Information Processing and Management",
volume = "45",
number = "4",
pages = "427 - 437",
year = "2009",
url = "http://www.sciencedirect.com/science/article/pii/S0306457309000259",
author = "Marina Sokolova and Guy Lapalme",
keywords = "Performance evaluation, Machine Learning, Text classification"
}

@book{Fellbaum:1998,
 author = {Christiane Fellbaum},
 Title = {WordNet: An Electronic Lexical Database},
 Year = {1998},
 Publisher = {MIT Press},
 address = {Cambridge, MA},
 Pages = {17--31}
}

@article{Miller:1995,
 author = {George A. Miller},
 year = {1995},
 title = {WordNet: A Lexical Database for English},
 journal = {Communications of the ACM},
 volume = {38},
 number = {11},
 pages = {39--41}
}

@article{Zhang:2006,
 author = {Zhang, M.L.; Zhou, Z.H.},
 year = {2006},
 title = {Multi-label neural networks with applications to functional genomics and text categorization},
 journal = {IEEE Transactions on Knowledge and Data Engineering},
 volume = {18},
 pages = {1338--1351}
}

@article{Zhang:2017,
 author = {Zhi Zhang and Guanghan Ning and Zhihai He},
 title = {Knowledge Projection for Deep Neural Networks},
 journal = {ArXiv e-prints},
 url = {https://arxiv.org/abs/1710.09505},
 year = {2017}
}

@article{Read:2011:CCM:2070617.2070629,
 author = {Read, Jesse and Pfahringer, Bernhard and Holmes, Geoff and Frank, Eibe},
 title = {Classifier Chains for Multi-label Classification},
 journal = {Mach. Learn.},
 volume = {85},
 number = {3},
 month = {12},
 year = {2011},
 pages = {333--359},
 numpages = {27},
 howpublished = {\url{http://dx.doi.org/10.1007/s10994-011-5256-5}},
 url = {http://dx.doi.org/10.1007/s10994-011-5256-5},
 acmid = {2070629},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Ensemble methods, Multi-label classification, Problem transformation, Scalable methods}
} 

@article{GongJLTI13,
  author    = {Yunchao Gong and Yangqing Jia and Thomas Leung and Alexander Toshev and Sergey Ioffe},
  title     = {Deep Convolutional Ranking for Multilabel Image Annotation},
  journal   = {CoRR},
  volume    = {abs/1312.4894},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.4894},
  archivePrefix = {arXiv},
  eprint    = {1312.4894},
  timestamp = {Wed, 07 Jun 2017 14:40:25 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/GongJLTI13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{SimonyanZ14a,
  author    = {Karen Simonyan and Andrew Zisserman},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1409.1556},
  year      = {2014},
  url       = {http://arxiv.org/abs/1409.1556},
  archivePrefix = {arXiv},
  eprint    = {1409.1556},
  timestamp = {Wed, 07 Jun 2017 14:41:51 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/SimonyanZ14a},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{DaveTEV16,
  author    = {Mihika Dave and Sahil Tapiawala and Meng Joo Er and Rajasekar Venkatesan},
  title     = {A Novel Progressive Multi-label Classifier for Classincremental Data},
  journal   = {CoRR},
  volume    = {abs/1609.07215},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.07215},
  archivePrefix = {arXiv},
  eprint    = {1609.07215},
  timestamp = {Wed, 07 Jun 2017 14:40:41 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/DaveTEV16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{WangYMHHX16,
  author    = {Jiang Wang and Yi Yang and Junhua Mao and Zhiheng Huang and Chang Huang and Wei Xu},
  title     = {{CNN-RNN:} {A} Unified Framework for Multi-label Image Classification},
  journal   = {CoRR},
  volume    = {abs/1604.04573},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.04573},
  archivePrefix = {arXiv},
  eprint    = {1604.04573},
  timestamp = {Wed, 07 Jun 2017 14:42:20 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/WangYMHHX16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{ZhuLOYW17,
  author    = {Feng Zhu and Hongsheng Li and Wanli Ouyang and Nenghai Yu and Xiaogang Wang},
  title     = {Learning Spatial Regularization with Image-level Supervisions for Multi-label Image Classification},
  journal   = {CoRR},
  volume    = {abs/1702.05891},
  year      = {2017},
  url       = {http://arxiv.org/abs/1702.05891},
  archivePrefix = {arXiv},
  eprint    = {1702.05891},
  timestamp = {Wed, 07 Jun 2017 14:42:45 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/ZhuLOYW17},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{WuZ16,
  author    = {Xi{-}Zhu Wu and Zhi{-}Hua Zhou},
  title     = {A Unified View of Multi-Label Performance Measures},
  journal   = {CoRR},
  volume    = {abs/1609.00288},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.00288},
  archivePrefix = {arXiv},
  eprint    = {1609.00288},
  timestamp = {Wed, 07 Jun 2017 14:42:08 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/WuZ16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@ARTICLE{2017arXiv171009230L,
   author = {{Loog}, M.},
    title = "{Supervised Classification: Quite a Brief Overview}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1710.09230},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
     year = {2017},
    month = {10},
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv171009230L},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2017arXiv171008049W,
   author = {{Wang}, T. and {Yamaguchi}, K. and {Ordonez}, V.},
    title = "{{Feedback-prop: Convolutional Neural Network Inference under Partial Evidence}}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1710.08049},
 primaryClass = "cs.CV",
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
     year = {2017},
    month = {10},
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv171008049W},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2015arXiv151105616H,
   author = {{Hu}, H. and {Zhou}, G.-T. and {Deng}, Z. and {Liao}, Z. and {Mori}, G.},
    title = {{Learning Structured Inference Neural Networks with Label Relations}},
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1511.05616},
 primaryClass = "cs.CV",
 keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning},
     year = {2015},
    month = {11},
   adsurl = {http://adsabs.harvard.edu/abs/2015arXiv151105616H},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2014arXiv1406.5726W,
   author = {{Wei}, Y. and {Xia}, W. and {Huang}, J. and {Ni}, B. and {Dong}, J. and {Zhao}, Y. and {Yan}, S.},
    title = {{CNN: Single-label to Multi-label}},
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1406.5726},
 primaryClass = "cs.CV",
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
     year = {2014},
    month = {6},
   adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1406.5726W},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2017arXiv171004908C,
   author = {{Chen}, M. and {Lin}, Z. and {Cho}, K.},
    title = {{Graph Convolutional Networks for Classification with a Structured Label Space}},
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1710.04908},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning, Statistics - Machine Learning},
     year = {2017},
    month = {10},
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv171004908C},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2015arXiv150308677A,
   author = {{Akata}, Z. and {Perronnin}, F. and {Harchaoui}, Z. and {Schmid}, C.},
    title = {{Label-Embedding for Image Classification}},
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1503.08677},
 primaryClass = "cs.CV",
 keywords = {Computer Science - Computer Vision and Pattern Recognition},
     year = 2015,
    month = mar,
   adsurl = {http://adsabs.harvard.edu/abs/2015arXiv150308677A},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{scikitML:2017, 
author = {{Szyma{\'n}ski}, P. and {Kajdanowicz}, T.}, 
title = "{A scikit-based Python environment for performing multi-label classification}",
journal = {ArXiv e-prints},
archivePrefix = "arXiv",
eprint = {1702.01460},
primaryClass = "cs.LG",
keywords = {Computer Science - Learning, Computer Science - Mathematical Software},
year = 2017,
month = feb,
}

@article{Kurata:2016,
	Abstract = {In a multi-label text classification task, in which multiple labels can be assigned to one text, label co-occurrence itself is informative. We propose a novel neural network initialization method to treat some of the neurons in the final hidden layer as dedicated neurons for each pattern of label co-occurrence. These dedicated neurons are initialized to connect to the corresponding co-occurring labels with stronger weights than to others. In experiments with a natural language query classification task, which requires multi-label classification, our initialization method improved classification accuracy without any computational overhead in training and evaluation.},
	Author = {Gakuto Kurata and Bing Xiang and Bowen Zhou},
	Journal = {Proceedings of NAAL-HLT},
	Title = {Improved Neural Network-based Multi-label Classification with Better Initialization Leveraging Label Co-occurrence},
	Numpages = {6},
	Pages = {521--526},
	Month = {6},
	Year = {2016}
}

@article{Vallet:2015,
author = {Vallet, Alexis and Sakamoto, Hiroyasu},
year = {2015},
month = {11},
pages = {767-775},
title = {A Multi-Label Convolutional Neural Network for Automatic Image Annotation},
volume = {23},
booktitle = {Journal of Information Processing}
}

@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal = {International Journal of Computer Vision (IJCV)},
volume={115},
number={3},
pages={211-252}
}

@article{MSCOCO,
  author    = {Tsung{-}Yi Lin and Michael Maire and Serge J. Belongie and Lubomir D. Bourdev and Ross B. Girshick and James Hays and Pietro Perona and Deva Ramanan and Piotr Doll{\'{a}}r and C. Lawrence Zitnick},
  title     = {{Microsoft {COCO:} Common Objects in Context}},
  journal   = {CoRR},
  volume    = {abs/1405.0312},
  year      = {2014},
  archivePrefix = {arXiv},
  eprint    = {1405.0312},
  timestamp = {Wed, 07 Jun 2017 14:41:35 +0200},
  url       = {http://arxiv.org/abs/1405.0312},
  biburl    = {http://dblp.org/rec/bib/journals/corr/LinMBHPRDZ14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


@article{Tsoumakas:2007,
title = {{Multi-Label Classification: An Overview}},
journal = {International Journal of Data Warehousing and Mining (IJDWM)},
year = {2007},
url = {http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/jdwm.2007070101},
author = {Grigorios Tsoumakas and Ioannis Katakis},
vol = {3},
issue = {3},
abstract = {Multi-label classification methods are increasingly required by modern applications, such as protein function classification, music categorization, and semantic scene classification. This article introduces the task of multi-label classification, organizes the sparse related literature into a structured presentation and performs comparative experimental results of certain multilabel classification methods. It also contributes the definition of concepts for the quantification of the multi-label nature of a data set.}
}

@article{Tsoumakas:2008,
author = {G. Tsoumakas, I. Katakis, I. Vlahavas},
title = {Effective and Efficient Multilabel Classification in Domains with Large Number of Labels},
journal = {Proc. ECML/PKDD 2008 Workshop on Mining Multidimensional Data},
year = {2008}
}

@Article{Spyromitros-Xioufis2016,
author="Spyromitros-Xioufis, Eleftherios and Tsoumakas, Grigorios and Groves, William and Vlahavas, Ioannis",
title="Multi-target regression via input space expansion: treating targets as inputs",
journal="Machine Learning",
year="2016",
month="Jul",
day="01",
volume="104",
number="1",
pages="55--98",
abstract="In many practical applications of supervised learning the task involves the prediction of multiple target variables from a common set of input variables. When the prediction targets are binary the task is called multi-label classification, while when the targets are continuous the task is called multi-target regression. In both tasks, target variables often exhibit statistical dependencies and exploiting them in order to improve predictive accuracy is a core challenge. A family of multi-label classification methods address this challenge by building a separate model for each target on an expanded input space where other targets are treated as additional input variables. Despite the success of these methods in the multi-label classification domain, their applicability and effectiveness in multi-target regression has not been studied until now. In this paper, we introduce two new methods for multi-target regression, called stacked single-target and ensemble of regressor chains, by adapting two popular multi-label classification methods of this family. Furthermore, we highlight an inherent problem of these methods---a discrepancy of the values of the additional input variables between training and prediction---and develop extensions that use out-of-sample estimates of the target variables during training in order to tackle this problem. The results of an extensive experimental evaluation carried out on a large and diverse collection of datasets show that, when the discrepancy is appropriately mitigated, the proposed methods attain consistent improvements over the independent regressions baseline. Moreover, two versions of Ensemble of Regression Chains perform significantly better than four state-of-the-art methods including regularization-based multi-task learning methods and a multi-objective random forest approach.",
url="https://doi.org/10.1007/s10994-016-5546-z"
}

@Inbook{Sechidis2011,
author="Sechidis, Konstantinos and Tsoumakas, Grigorios and Vlahavas, Ioannis",
_editor="Gunopulos, Dimitrios and Hofmann, Thomas and Malerba, Donato and Vazirgiannis, Michalis",
title="On the Stratification of Multi-label Data",
bookTitle="Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2011, Athens, Greece, September 5-9, 2011, Proceedings, Part III",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="145--158",
abstract="Stratified sampling is a sampling method that takes into account the existence of disjoint groups within a population and produces samples where the proportion of these groups is maintained. In single-label classification tasks, groups are differentiated based on the value of the target variable. In multi-label learning tasks, however, where there are multiple target variables, it is not clear how stratified sampling could/should be performed. This paper investigates stratification in the multi-label data context. It considers two stratification methods for multi-label data and empirically compares them along with random sampling on a number of datasets and based on a number of evaluation criteria. The results reveal some interesting conclusions with respect to the utility of each method for particular types of multi-label datasets.",
url="https://doi.org/10.1007/978-3-642-23808-6_10"
}

@inproceedings{MNIST,
author = {Y. LeCun and L. Bottou and Y. Bengio and P. Haffner},
title = {{Gradient-based learning applied to document recognition}},
booktitle = {Proc. of the IEEE},
volume = {86},
pages = {2278--2324},
year = {1998}
}

@article{Krizhevsky2009,
 author = {{Krizhevsky, A.} and {Hinton, G.}},
 title={{Learning Multiple Layers of Features from Tiny Images}},
 year = {2009},
 journal = {Master's thesis, Department of Computer Science, University of Toronto},
 publisher = {Citeseer}
}

@inproceedings{nus-wide-civr09,
  author={Tat-Seng Chua and Jinhui Tang and Richang Hong and Haojie Li and Zhiping Luo and Yan-Tao Zheng},
  booktitle={Proc. of ACM Conf. on Image and Video Retrieval (CIVR'09)},
  posted-at={July 8-10, 2009},
  title={{NUS-WIDE: A Real-World Web Image Database from National University of Singapore}},
  address={Santorini, Greece. },
  year={July 8-10, 2009},
  url={http://lms.comp.nus.edu.sg/research/NUS-WIDE.htm}
}

@inproceedings{Kohavi_1995_1137,
author = {R. Kohavi},
title = {{A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection}},
booktitle = {Proc. of the Int. Joint Conf. on Artificial Intelligence},
volume = {14},
pages = {1137–1143},
year = {1995}
}

@misc{chollet2015keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  publisher={GitHub},
  howpublished={\url{https://github.com/fchollet/keras}}
}

@misc{Lavrenko_2014,
  title={{Evaluation 12: mean average precision}},
  author={Lavrenko, Victor},
  year={2014},
  publisher={YouTube},
  howpublished={\url{https://www.youtube.com/watch?v=pM6DJ0ZZee0&list=PLBv09BD7ez_6nqE9YU9bQXpjJ5jJ1Kgr9&index=12}}
}

@article{CIFAR-10,
title= {CIFAR-10 (Canadian Institute for Advanced Research)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {},
url= {http://www.cs.toronto.edu/~kriz/cifar.html},
abstract= {The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. 
The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. },
keywords= {Dataset},
terms= {}
}

