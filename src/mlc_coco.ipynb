{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from glob import glob\n",
    "from PIL import Image, ImageFile\n",
    "\n",
    "# matplotlib.use('nbAgg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 18\n",
    "BIGGEST_SIZE = 22\n",
    "plt.rc('font', size=BIGGEST_SIZE)         # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGEST_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGEST_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)   # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)   # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)   # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGEST_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import label_ranking_loss\n",
    "from sklearn.metrics import coverage_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training, Validation, and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from coco import CocoGenerator\n",
    "\n",
    "subset_name = '2017'\n",
    "\n",
    "coco_train_gen = CocoGenerator(subset_name=subset_name, split_name='train')\n",
    "coco_train_sums_0 = np.sum(coco_train_gen.labels, axis=0, dtype=np.uint32)\n",
    "coco_train_sums_1 = np.sum(coco_train_gen.labels, axis=1, dtype=np.uint8)\n",
    "idx = np.random.randint(coco_train_gen.num_samples)\n",
    "img = coco_train_gen.load_image(idx)[0]\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(coco_train_gen.labels.shape, idx, img.shape, img.min(), img.max())\n",
    "print(coco_train_gen.label_names[np.where(coco_train_gen.labels[idx])[0]])\n",
    "\n",
    "coco_valid_gen = CocoGenerator(subset_name=subset_name, split_name='valid')\n",
    "coco_valid_sums_0 = np.sum(coco_valid_gen.labels, axis=0, dtype=np.uint32)\n",
    "coco_valid_sums_1 = np.sum(coco_valid_gen.labels, axis=1, dtype=np.uint8)\n",
    "idx = np.random.randint(coco_valid_gen.num_samples)\n",
    "img = coco_valid_gen.load_image(idx)[0]\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(coco_valid_gen.labels.shape, idx, img.shape, img.min(), img.max())\n",
    "print(coco_valid_gen.label_names[np.where(coco_valid_gen.labels[idx])[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_train = np.max(coco_train_sums_1)\n",
    "max_valid = np.max(coco_valid_sums_1)\n",
    "max_tvt = np.max([max_train, max_valid])\n",
    "n_images_with_k_tags_dict = {'train': [0]*int(max_tvt+1), 'valid': [0]*int(max_tvt+1)}\n",
    "\n",
    "for s in coco_train_sums_1:\n",
    "    n_images_with_k_tags_dict['train'][s] += 1\n",
    "for s in coco_valid_sums_1:\n",
    "    n_images_with_k_tags_dict['valid'][s] += 1\n",
    "\n",
    "n_images_with_k_tags_df = pd.DataFrame(n_images_with_k_tags_dict)\n",
    "n_images_with_k_tags_df.plot(kind='bar', figsize=[16, 3], secondary_y=('valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_images_with_k_tags_df.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images_per_tag_dict = {'train': coco_train_sums_0, 'valid': coco_valid_sums_0}\n",
    "images_per_tag_df = pd.DataFrame(images_per_tag_dict, index=coco_train_gen.label_names)\n",
    "images_per_tag_df.plot(kind='bar', figsize=[16, 3], secondary_y=('valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images_per_tag_df.style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Top Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transfer import KerasTransfer\n",
    "\n",
    "kt = KerasTransfer(\n",
    "    dataset='coco',\n",
    "    subset='2017',\n",
    "    base_pooling='avg',\n",
    "    pp_method='zmuv',\n",
    "    hidden_size_1=4096,\n",
    "    hidden_size_2=4096,\n",
    "    batch_norm=False,\n",
    "    dropout=5,\n",
    "    learn_rate_pretrain=(1, 1),\n",
    "    batch_size_pretrain=32,\n",
    "    resume_pretraining=True,\n",
    "    epochs=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(kt.top_model_weights_file)\n",
    "kt.pretrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kt.load_final_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_top_model_template = '../data/bottleneck_top_models/coco*.csv'\n",
    "min_losses = []\n",
    "for csv_file in sorted(glob(csv_top_model_template)):\n",
    "    csv_basefile = csv_file.rsplit(os.sep, maxsplit=1)[1]\n",
    "    csv_data = pd.read_csv(csv_file)\n",
    "    min_idx = np.argmin(csv_data.val_loss)\n",
    "    n_epochs = len(csv_data.val_loss)\n",
    "    min_losses.append((csv_basefile, n_epochs, n_epochs - min_idx, csv_data.val_loss[min_idx]))\n",
    "\n",
    "for label, n_ep, from_end, min_loss in sorted(min_losses, key=lambda x: x[3]):\n",
    "    print(\"{:8.5f} {:3} {:2} {}\".format(min_loss, n_ep, from_end, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pset = ('coco', '2017', 'zmuv', 'avg', '1x2048bn', ['lr52', 'lr32', 'lr22', 'lr12', 'lr83', 'lr53', 'lr13'], 'b64')\n",
    "\n",
    "colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k']\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(13, 9))\n",
    "\n",
    "min_losses = []\n",
    "in_prefix = True\n",
    "prefix_list = []\n",
    "suffix_list = []\n",
    "for field in pset:\n",
    "    if isinstance(field, str):\n",
    "        if in_prefix:\n",
    "            prefix_list.append(field)\n",
    "        else:\n",
    "            suffix_list.append(field)\n",
    "    elif isinstance(field, list):\n",
    "        labels = field\n",
    "        in_prefix = False\n",
    "prefix = '_'.join(prefix_list)\n",
    "suffix = '_'.join(suffix_list)\n",
    "pset_title = '_'.join([prefix, \"????\", suffix])\n",
    "labelsA = [l + ' (train)' for l in labels]\n",
    "labelsB = [l + ' (val)' for l in labels]\n",
    "legend_labels = []\n",
    "for k, label in enumerate(labels):\n",
    "\n",
    "    csv_basefile = '_'.join([prefix, label, suffix])\n",
    "    csv_file = \"../data/bottleneck_top_models/\" + csv_basefile + \".csv\"\n",
    "    csv_data = pd.read_csv(csv_file)\n",
    "    csv_data.loss.plot(ax=axes, color=colors[k % len(colors)], style='--')\n",
    "    csv_data.val_loss.plot(ax=axes, color=colors[k % len(colors)])\n",
    "    legend_labels.append(labelsA[k])\n",
    "    legend_labels.append(labelsB[k])\n",
    "    \n",
    "axes.set_title(pset_title)\n",
    "axes.set_ylim((0.05, 0.16))\n",
    "axes.set_xlabel(r'Epoch', {'fontsize': 20})\n",
    "axes.set_ylabel(r'Loss', {'fontsize': 20})\n",
    "axes.legend(legend_labels, loc='upper right', bbox_to_anchor=(0.98, 0.97))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_pl_c = [\n",
    "    (\"inet\", \"77\", \"k\"),\n",
    "    (\"inet\", \"max\", \"r\"),\n",
    "    (\"inet\", \"avg\", \"g\"),\n",
    "    (\"zmuv\", \"77\", \"c\"),\n",
    "    (\"zmuv\", \"max\", \"y\"),\n",
    "    (\"zmuv\", \"avg\", \"b\"),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(8, 5))\n",
    "legend_labels = []\n",
    "for pp, pl, c in pp_pl_c:\n",
    "    csv_file = \"../data/bottleneck_top_models/coco_2017_\" + pp + \"_\" + pl + \"_1x1024d5_lr11_b32.csv\"\n",
    "    csv_data = pd.read_csv(csv_file)\n",
    "    axes.plot(csv_data.epoch, csv_data.val_loss, color=c)\n",
    "    legend_labels.append(', '.join([pp, pl]))\n",
    "    \n",
    "axes.set_title(\"coco_2017_????_???_1x1024d5_lr11_b32\")\n",
    "axes.set_xlabel(r'Epoch')\n",
    "axes.set_ylabel(r'Validation Loss')\n",
    "# axes.set_ylim((0.065, 0.085))\n",
    "axes.legend(legend_labels, ncol=2, loc='upper right', bbox_to_anchor=(0.99, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_sz_c = [\n",
    "    (\"max\", \"1024\", \"y\"),\n",
    "    (\"max\", \"2048\", \"r\"),\n",
    "    (\"max\", \"4096\", \"g\"),\n",
    "    (\"avg\", \"1024\", \"b\"),\n",
    "    (\"avg\", \"2048\", \"c\"),\n",
    "    (\"avg\", \"4096\", \"m\"),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(8, 5))\n",
    "legend_labels = []\n",
    "for pl, sz, c in pl_sz_c:\n",
    "    csv_file = \"../data/bottleneck_top_models/coco_2017_zmuv_\" + pl + \"_1x\" + sz + \"d5_lr11_b32.csv\"\n",
    "    csv_data = pd.read_csv(csv_file)\n",
    "    axes.plot(csv_data.epoch, csv_data.val_loss, color=c)\n",
    "    legend_labels.append(', '.join([pl, sz]))\n",
    "    \n",
    "axes.set_title(\"coco_2017_zmuv_???_1x????d5_lr11_b32\")\n",
    "axes.set_xlabel(r'Epoch')\n",
    "axes.set_ylabel(r'Validation Loss')\n",
    "# axes.set_ylim((0.065, 0.085))\n",
    "axes.legend(legend_labels, ncol=2, loc='upper right', bbox_to_anchor=(0.99, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_dict = {'nl': ['1', '2'], 'sz': ['1024', '2048', '4096'], 'lr': ['11', '52'], 'bs': ['32', '64', '128']}\n",
    "\n",
    "epoch_time = {\n",
    "    (\"1\", \"1024\", \"32\"): 17.5,\n",
    "    (\"1\", \"1024\", \"64\"): 9.,\n",
    "    (\"1\", \"1024\", \"128\"): 5.,\n",
    "    (\"1\", \"1024\", \"256\"): 2.5,\n",
    "    (\"1\", \"2048\", \"32\"): 18.,\n",
    "    (\"1\", \"2048\", \"64\"): 9.,\n",
    "    (\"1\", \"2048\", \"128\"): 5.,\n",
    "    (\"1\", \"2048\", \"256\"): 2.5,\n",
    "    (\"1\", \"4096\", \"32\"): 19.,\n",
    "    (\"1\", \"4096\", \"64\"): 10.,\n",
    "    (\"1\", \"4096\", \"128\"): 5.,\n",
    "    (\"1\", \"4096\", \"256\"): 3.,\n",
    "    (\"2\", \"1024\", \"32\"): 19.,\n",
    "    (\"2\", \"1024\", \"64\"): 10.,\n",
    "    (\"2\", \"1024\", \"128\"): 6.,\n",
    "    (\"2\", \"1024\", \"256\"): 3.2,\n",
    "    (\"2\", \"2048\", \"32\"): 22.,\n",
    "    (\"2\", \"2048\", \"64\"): 12.,\n",
    "    (\"2\", \"2048\", \"128\"): 8.,\n",
    "    (\"2\", \"2048\", \"256\"): 4.2,\n",
    "    (\"2\", \"4096\", \"32\"): 28.,\n",
    "    (\"2\", \"4096\", \"64\"): 18.,\n",
    "    (\"2\", \"4096\", \"128\"): 11.,\n",
    "    (\"2\", \"4096\", \"256\"): 6.5,\n",
    "    (\"2\", \"4096\", \"512\"): 4.,\n",
    "}\n",
    "\n",
    "RUST = '#d62728'\n",
    "PINK = '#e377c2'\n",
    "GREY = '#7f7f7f'\n",
    "BROWN = '#8c564b'\n",
    "PURPLE = '#9467bd'\n",
    "ORANGE = '#ff7f0e'\n",
    "SEA_BLUE = '#1f77b4'\n",
    "LIME_GREEN = '#32cd32'\n",
    "LIGHT_SALMON = '#FFA07A'\n",
    "\n",
    "special_color = {\n",
    "    \"coco_2017_zmuv_avg_1x1096d5_lr11_b128\": LIME_GREEN,\n",
    "    \"coco_2017_zmuv_avg_1x2048d5_lr11_b128\": 'g',\n",
    "    \"coco_2017_zmuv_avg_1x4096d5_lr11_b128\": 'y',\n",
    "    \"coco_2017_zmuv_avg_1x4096d5_lr52_b128\": RUST,\n",
    "    \"coco_2017_zmuv_avg_2x1024d5_lr11_b128\": ORANGE,\n",
    "    \"coco_2017_zmuv_avg_2x1024d5_lr52_b128\": BROWN,\n",
    "    \"coco_2017_zmuv_avg_2x2048d5_lr11_b128\": 'r',\n",
    "    \"coco_2017_zmuv_avg_2x2048d5_lr52_b128\": PINK,\n",
    "    \"coco_2017_zmuv_avg_2x4096d5_lr11_b32\": PURPLE,\n",
    "    \"coco_2017_zmuv_avg_2x4096d5_lr11_b64\": 'm',\n",
    "    \"coco_2017_zmuv_avg_2x4096d5_lr11_b128\": 'c',\n",
    "    \"coco_2017_zmuv_avg_2x4096d5_lr52_b32\": GREY,\n",
    "    \"coco_2017_zmuv_avg_2x4096d5_lr52_b64\": LIGHT_SALMON,\n",
    "    \"coco_2017_zmuv_avg_2x4096d5_lr52_b128\": 'b',\n",
    "    \"coco_2017_zmuv_avg_2x4096d5_lr11_b256\": 'k',\n",
    "}\n",
    "\n",
    "def plot_compare(const_dict, var_arr, in_seconds=False, ylim=(0.065, 0.085), xlim=None, ncol=2):\n",
    "    \n",
    "    def get_var():\n",
    "        if a_is_free:\n",
    "            v = a\n",
    "            a_is_free = False\n",
    "        elif b_is_free:\n",
    "            v = b\n",
    "            b_is_free = False\n",
    "        else:\n",
    "            raise ValueError\n",
    "        return v\n",
    "\n",
    "    top_models_dir = \"../data/bottleneck_top_models/\"\n",
    "    coco_prefix = \"coco_2017_zmuv_avg_\"\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(8, 5))\n",
    "    legend_labels = []\n",
    "    for a, b, c in var_arr:\n",
    "        a_is_free = True\n",
    "        b_is_free = True\n",
    "        csv_basename = coco_prefix\n",
    "        \n",
    "        if 'nl' in const_dict:\n",
    "            nl = const_dict['nl']\n",
    "        else:\n",
    "            if a_is_free:\n",
    "                v = a\n",
    "                a_is_free = False\n",
    "            elif b_is_free:\n",
    "                v = b\n",
    "                b_is_free = False\n",
    "            else:\n",
    "                raise ValueError\n",
    "            nl = v\n",
    "            \n",
    "        if 'sz' in const_dict:\n",
    "            sz = const_dict['sz']\n",
    "        else:\n",
    "            if a_is_free:\n",
    "                v = a\n",
    "                a_is_free = False\n",
    "            elif b_is_free:\n",
    "                v = b\n",
    "                b_is_free = False\n",
    "            else:\n",
    "                raise ValueError\n",
    "            sz = v\n",
    "        \n",
    "        if 'lr' in const_dict:\n",
    "            lr = const_dict['lr']\n",
    "        else:\n",
    "            if a_is_free:\n",
    "                v = a\n",
    "                a_is_free = False\n",
    "            elif b_is_free:\n",
    "                v = b\n",
    "                b_is_free = False\n",
    "            else:\n",
    "                raise ValueError\n",
    "            lr = v\n",
    "        \n",
    "        if 'bs' in const_dict:\n",
    "            bs = const_dict['bs']\n",
    "        else:\n",
    "            if a_is_free:\n",
    "                v = a\n",
    "                a_is_free = False\n",
    "            elif b_is_free:\n",
    "                v = b\n",
    "                b_is_free = False\n",
    "            else:\n",
    "                raise ValueError\n",
    "            bs = v\n",
    "            \n",
    "        csv_basename += nl + 'x' + sz + 'd5_lr' + lr + '_b' + bs\n",
    "        \n",
    "        if not os.path.exists(top_models_dir + csv_basename + \".csv\"):\n",
    "            continue\n",
    "            \n",
    "        color = special_color.get(csv_basename, c)\n",
    "        csv_data = pd.read_csv(top_models_dir + csv_basename + \".csv\")\n",
    "        xscale = epoch_time[(nl, sz, bs)] if in_seconds else 1\n",
    "        axes.plot(csv_data.epoch * xscale, csv_data.val_loss, color=c)\n",
    "        legend_labels.append(', '.join([a, b]))\n",
    "\n",
    "    title = ''\n",
    "    title += const_dict['nl'] if 'nl' in const_dict else '?'\n",
    "    title += 'x'\n",
    "    title += const_dict['sz'] if 'sz' in const_dict else '????'\n",
    "    title += 'd5_lr'\n",
    "    title += const_dict['lr'] if 'lr' in const_dict else '??'\n",
    "    title += '_b'\n",
    "    title += const_dict['bs'] if 'bs' in const_dict else '??'\n",
    "        \n",
    "    if ncol >= 3:\n",
    "        fontsize = 13\n",
    "    else:\n",
    "        fontsize = 16\n",
    "    axes.set_title(coco_prefix + title)\n",
    "    xlabel = r'Time (s)' if in_seconds else r'Epoch'\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(r'Validation Loss')\n",
    "    if xlim is not None:\n",
    "        axes.set_xlim(xlim)\n",
    "        \n",
    "    axes.set_ylim(ylim)\n",
    "#     axes.legend(legend_labels, ncol=ncol, loc='upper right', bbox_to_anchor=(0.99, 0.99), fontsize=fontsize)\n",
    "    axes.legend(legend_labels, ncol=ncol, loc='upper right', bbox_to_anchor=(0.99, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nl_sz_c = [\n",
    "    (\"1\", \"1024\", LIME_GREEN),\n",
    "    (\"1\", \"2048\", 'g'),\n",
    "    (\"1\", \"4096\", \"y\"),\n",
    "    (\"2\", \"1024\", ORANGE),\n",
    "    (\"2\", \"2048\", \"r\"),\n",
    "    (\"2\", \"4096\", \"c\"),\n",
    "]\n",
    "fixed_vals = ['lr', 'bs']\n",
    "for const_a in hyper_dict[fixed_vals[0]]:\n",
    "    for const_b in hyper_dict[fixed_vals[1]]:\n",
    "        const_args = {fixed_vals[0]: const_a, fixed_vals[1]: const_b}\n",
    "        plot_compare(const_args, nl_sz_c, ncol=1, xlim=(0, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nl_lr_c = [\n",
    "    (\"1\", \"52\", RUST),\n",
    "    (\"1\", \"11\", \"y\"),\n",
    "    (\"2\", \"52\", \"b\"),\n",
    "    (\"2\", \"11\", \"c\"),\n",
    "]\n",
    "fixed_vals = ['sz', 'bs']\n",
    "for const_a in hyper_dict[fixed_vals[0]]:\n",
    "    for const_b in hyper_dict[fixed_vals[1]]:\n",
    "        const_args = {fixed_vals[0]: const_a, fixed_vals[1]: const_b}\n",
    "        plot_compare(const_args, nl_lr_c, ncol=1, xlim=(0, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nl_bs_c = [\n",
    "    (\"1\", \"128\", \"g\"),\n",
    "    (\"1\", \"64\", \"c\"),\n",
    "    (\"1\", \"32\", \"b\"),\n",
    "    (\"2\", \"128\", \"m\"),\n",
    "    (\"2\", \"64\", \"r\"),\n",
    "    (\"2\", \"32\", \"y\"),\n",
    "]\n",
    "fixed_vals = ['sz', 'lr']\n",
    "for const_a in hyper_dict[fixed_vals[0]]:\n",
    "    for const_b in hyper_dict[fixed_vals[1]]:\n",
    "        const_args = {fixed_vals[0]: const_a, fixed_vals[1]: const_b}\n",
    "        plot_compare(const_args, nl_bs_c, ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nl_bs_c = [\n",
    "    (\"1\", \"32\", \"b\"),\n",
    "    (\"1\", \"64\", \"c\"),\n",
    "    (\"1\", \"128\", \"g\"),\n",
    "    (\"2\", \"32\", \"y\"),\n",
    "    (\"2\", \"64\", \"r\"),\n",
    "    (\"2\", \"128\", \"m\"),\n",
    "]\n",
    "fixed_vals = ['sz', 'lr']\n",
    "for const_a in hyper_dict[fixed_vals[0]]:\n",
    "    for const_b in hyper_dict[fixed_vals[1]]:\n",
    "        const_args = {fixed_vals[0]: const_a, fixed_vals[1]: const_b}\n",
    "        plot_compare(const_args, nl_bs_c, in_seconds=True, ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sz_lr_c = [\n",
    "    (\"1024\", \"52\", BROWN),\n",
    "    (\"2048\", \"52\", PINK),\n",
    "    (\"4096\", \"52\", 'b'),\n",
    "    (\"1024\", \"11\", ORANGE),\n",
    "    (\"2048\", \"11\", \"r\"),\n",
    "    (\"4096\", \"11\", \"c\"),\n",
    "]\n",
    "fixed_vals = ['nl', 'bs']\n",
    "for const_a in hyper_dict[fixed_vals[0]]:\n",
    "    for const_b in hyper_dict[fixed_vals[1]]:\n",
    "        const_args = {fixed_vals[0]: const_a, fixed_vals[1]: const_b}\n",
    "        plot_compare(const_args, sz_lr_c, ncol=1, xlim=(0, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sz_bs_c = [\n",
    "    (\"1024\", \"128\", SEA_BLUE),\n",
    "    (\"2048\", \"128\", RUST),\n",
    "    (\"4096\", \"128\", PINK),\n",
    "    (\"1024\", \"64\", ORANGE),\n",
    "    (\"2048\", \"64\", PURPLE),\n",
    "    (\"4096\", \"64\", GREY),\n",
    "    (\"1024\", \"32\", LIME_GREEN),\n",
    "    (\"2048\", \"32\", BROWN),\n",
    "    (\"4096\", \"32\", LIGHT_SALMON),\n",
    "]\n",
    "fixed_vals = ['nl', 'lr']\n",
    "for const_a in hyper_dict[fixed_vals[0]]:\n",
    "    for const_b in hyper_dict[fixed_vals[1]]:\n",
    "        const_args = {fixed_vals[0]: const_a, fixed_vals[1]: const_b}\n",
    "        plot_compare(const_args, sz_bs_c, ncol=3, ylim=(0.066, 0.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sz_bs_c = [\n",
    "    (\"1024\", \"128\", SEA_BLUE),\n",
    "    (\"2048\", \"128\", RUST),\n",
    "    (\"4096\", \"128\", PINK),\n",
    "    (\"1024\", \"64\", ORANGE),\n",
    "    (\"2048\", \"64\", PURPLE),\n",
    "    (\"4096\", \"64\", GREY),\n",
    "    (\"1024\", \"32\", LIME_GREEN),\n",
    "    (\"2048\", \"32\", BROWN),\n",
    "    (\"4096\", \"32\", LIGHT_SALMON),\n",
    "]\n",
    "fixed_vals = ['nl', 'lr']\n",
    "for const_a in hyper_dict[fixed_vals[0]]:\n",
    "    for const_b in hyper_dict[fixed_vals[1]]:\n",
    "        const_args = {fixed_vals[0]: const_a, fixed_vals[1]: const_b}\n",
    "        plot_compare(const_args, sz_bs_c, in_seconds=True, ncol=3, ylim=(0.066, 0.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr_bs_c = [\n",
    "    (\"11\", \"64\", 'm'),\n",
    "    (\"52\", \"32\", GREY),\n",
    "    (\"11\", \"128\", 'c'),\n",
    "    (\"52\", \"64\", LIGHT_SALMON),\n",
    "    (\"11\", \"256\", 'k'),\n",
    "    (\"52\", \"128\", 'b'),\n",
    "]\n",
    "\n",
    "fixed_vals = ['nl', 'sz']\n",
    "for const_a in hyper_dict[fixed_vals[0]]:\n",
    "    for const_b in hyper_dict[fixed_vals[1]]:\n",
    "        const_args = {fixed_vals[0]: const_a, fixed_vals[1]: const_b}\n",
    "        plot_compare(const_args, lr_bs_c, ncol=3, xlim=(0, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr_bs_c = [\n",
    "    (\"11\", \"64\", 'm'),\n",
    "    (\"11\", \"128\", 'c'),\n",
    "    (\"11\", \"256\", 'k'),\n",
    "    (\"52\", \"32\", GREY),\n",
    "    (\"52\", \"64\", LIGHT_SALMON),\n",
    "    (\"52\", \"128\", 'b'),\n",
    "]\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(8, 5))\n",
    "# legend_labels = []\n",
    "# for lr, bs, c in lr_bs_c:\n",
    "#     csv_file = \"../data/bottleneck_top_models/coco_2017_zmuv_avg_2x4096d5_lr\" + lr + \"_b\" + bs + \".csv\"\n",
    "#     csv_data = pd.read_csv(csv_file)\n",
    "#     axes.plot(csv_data.epoch * epoch_time[bs], csv_data.val_loss, color=c)\n",
    "#     legend_labels.append(', '.join([lr, bs]))\n",
    "    \n",
    "# axes.set_title(\"coco_2017_zmuv_avg_2x4096d5_lr??_b??\", {'fontsize': 20})\n",
    "# axes.set_xlabel(r'Time (s)', {'fontsize': 20})\n",
    "# axes.set_ylabel(r'Validation Loss', {'fontsize': 20})\n",
    "# axes.set_ylim((0.065, 0.085))\n",
    "# axes.legend(legend_labels, ncol=2, loc='upper right', bbox_to_anchor=(0.98, 0.97))\n",
    "\n",
    "fixed_vals = ['nl', 'sz']\n",
    "for const_a in hyper_dict[fixed_vals[0]]:\n",
    "    for const_b in hyper_dict[fixed_vals[1]]:\n",
    "        const_args = {fixed_vals[0]: const_a, fixed_vals[1]: const_b}\n",
    "        plot_compare(const_args, lr_bs_c, in_seconds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_basefiles = {\n",
    "    \"coco_2017_zmuv_avg_1x1024d5_lr11_b16\": \"r\",\n",
    "    \"coco_2017_zmuv_avg_1x1024d5_lr12_b16\": \"c\",\n",
    "    \"coco_2017_zmuv_avg_1x1024d5_lr13_b04\": \"b\",\n",
    "    \"coco_2017_zmuv_avg_1x1024d5_lr11_b32\": \"g\",\n",
    "    \"coco_2017_zmuv_avg_1x1024d5_lr12_b32\": \"m\",\n",
    "    \"coco_2017_zmuv_avg_1x1024d5_lr13_b32\": \"y\",\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(8, 5))\n",
    "\n",
    "for csv_basefile, color in csv_basefiles.items():\n",
    "    csv_file = \"../data/bottleneck_top_models/\" + csv_basefile + \".csv\"\n",
    "    csv_data = pd.read_csv(csv_file)\n",
    "    csv_data.val_loss.plot(ax=axes, color=color)\n",
    "\n",
    "axes.set_title(\"coco_2017_zmuv_avg_1x1024d5_????_???\", {'fontsize': 20})\n",
    "axes.set_xlabel(r'Epoch', {'fontsize': 20})\n",
    "axes.set_ylabel(r'Validation Loss', {'fontsize': 20})\n",
    "legend_labels = ['lr11, b16', 'lr12, b16', 'lr13, b16', 'lr11, b32', 'lr12, b32', 'lr13, b32']\n",
    "axes.legend(legend_labels, ncol=2, loc='upper right', bbox_to_anchor=(0.98, 0.97))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transfer import KerasTransfer\n",
    "\n",
    "kt = KerasTransfer(\n",
    "    dataset='coco',\n",
    "    subset='2017',\n",
    "    base_pooling='avg',\n",
    "    pp_method='zmuv',\n",
    "    hidden_size_1=4096,\n",
    "    hidden_size_2=4096,\n",
    "    batch_norm=False,\n",
    "    dropout=5,\n",
    "    learn_rate_pretrain=(1, 1),\n",
    "    batch_size_pretrain=32,\n",
    "    resume_pretraining=True,\n",
    "    n_frozen=15,\n",
    "    learn_rate=(1, 1),\n",
    "    batch_size=128,\n",
    "    epochs=500,\n",
    "    transform_flags='hwrszf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kt.load_top_model()\n",
    "print(kt.final_weights_file)\n",
    "kt.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_top_model_template = '../data/final_weights/coco*.csv'\n",
    "min_losses = []\n",
    "for csv_file in sorted(glob(csv_top_model_template)):\n",
    "    csv_basefile = csv_file.rsplit(os.sep, maxsplit=1)[1]\n",
    "    csv_data = pd.read_csv(csv_file)\n",
    "    min_idx = np.argmin(csv_data.val_loss)\n",
    "    n_epochs = len(csv_data.val_loss)\n",
    "    min_losses.append((csv_basefile, n_epochs, n_epochs - min_idx, csv_data.val_loss[min_idx]))\n",
    "\n",
    "for label, n_ep, from_end, min_loss in sorted(min_losses, key=lambda x: x[3]):\n",
    "    print(\"{:8.5f} {:3} {:2} {}\".format(min_loss, n_ep, from_end, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and Evaluation COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transfer import KerasTransfer\n",
    "from coco import CocoGenerator\n",
    "import metrics\n",
    "\n",
    "valid_generator = CocoGenerator(split_name='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_name = '2017'\n",
    "\n",
    "kt = KerasTransfer(\n",
    "    dataset='coco',\n",
    "    subset=subset_name,\n",
    "    base_pooling='avg',\n",
    "    pp_method='zmuv',\n",
    "    hidden_size_1=4096,\n",
    "    hidden_size_2=4096,\n",
    "    batch_norm=False,\n",
    "    learn_rate_pretrain=(1, 1),\n",
    "    batch_size_pretrain=32,\n",
    "    n_frozen=15,\n",
    "    learn_rate=(1, 1),\n",
    "    batch_size=128,\n",
    "    epochs=500,\n",
    "    transform_flags='hwrszf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and F1 score on all results matching csv_top_model_template\n",
    "csv_top_model_template = '../data/final_weights/coco*.csv'\n",
    "to_skip = [\n",
    "    'coco_2017_zmuv_avg_1x2048bn_lr12_b64_15_lr12_b64_f',\n",
    "    'coco_2017_zmuv_avg_2x4096d5_lr11_b128_15_lr11_b128_hwrszf'\n",
    "]\n",
    "min_losses = []\n",
    "\n",
    "for csv_file in sorted(glob(csv_top_model_template)):\n",
    "    csv_basefile = csv_file.rsplit(os.sep, maxsplit=1)[1]\n",
    "    basefile = csv_basefile.rsplit('.', maxsplit=1)[0]\n",
    "\n",
    "    if basefile in to_skip:\n",
    "        continue\n",
    "\n",
    "    csv_data = pd.read_csv(csv_file)\n",
    "    min_idx = np.argmin(csv_data.val_loss)\n",
    "    min_loss = csv_data.val_loss[min_idx]\n",
    "    min_losses.append((basefile, min_loss))\n",
    "\n",
    "for basefile, min_loss in sorted(min_losses, key=lambda x: x[1]):\n",
    "\n",
    "    kt = KerasTransfer(model_basefilename=basefile)\n",
    "    y_pred_f32 = kt.load_predictions('valid')\n",
    "    y_test_f64 = kt.load_labels('valid')\n",
    "    y_test_f32 = y_test_f64.astype(np.float32)\n",
    "    y_test_ui8 = y_test_f32.astype(np.uint8)\n",
    "    y_test_bool = y_test_ui8.astype(np.bool_)\n",
    "\n",
    "    indices_k3 = np.where(np.sum(y_test_bool, axis=1) == 3)[0]\n",
    "    y_pred_f32 = y_pred_f32[indices_k3]\n",
    "    y_test_f32 = y_test_f32[indices_k3]\n",
    "    y_test_ui8 = y_test_ui8[indices_k3]\n",
    "    y_test_bool = y_test_bool[indices_k3]\n",
    "\n",
    "    y_pred_bool_k = metrics.get_k_predictions(y_test_f32, y_pred_f32)\n",
    "    y_pred_bool_3 = metrics.get_k_predictions(y_test_f32, y_pred_f32, k=3)\n",
    "\n",
    "    macro_k = metrics.get_precision_recall_fscore(y_test_bool, y_pred_bool_k, 'macro')\n",
    "    micro_k = metrics.get_precision_recall_fscore(y_test_bool, y_pred_bool_k, 'micro')\n",
    "    macro_3 = metrics.get_precision_recall_fscore(y_test_bool, y_pred_bool_3, 'macro')\n",
    "    micro_3 = metrics.get_precision_recall_fscore(y_test_bool, y_pred_bool_3, 'micro')\n",
    "    print('{0[0]:>.1%} {0[1]:>.1%} {0[2]:>.1%} | {1[2]:>.1%} | {2[0]:>.1%} {2[1]:>.1%} {2[2]:>.1%} | {3[0]:>.1%} {3[1]:>.1%} {3[2]:>.1%} | {4:>6.4f} {5}'.format(macro_k, micro_k, macro_3, micro_3, min_loss, basefile.split('avg_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kt = KerasTransfer(model_basefilename='coco_2017_zmuv_avg_2x4096d5_lr11_b256_15_lr11_b128_hwrszf')\n",
    "# Augmenting a dataset takes time. Let's do it once and keep a reference to them.\n",
    "# y_pred_f32_aug = kt.make_predictions('valid', augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_f32 = kt.load_predictions('valid')\n",
    "# y_pred_f32 = y_pred_f32_aug\n",
    "print(type(y_pred_f32[1, 1]), y_pred_f32.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_f64 = kt.load_labels('valid')\n",
    "print(type(y_test_f64[1, 1]), y_test_f64.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_ui8 = kt.load_tensors('valid')\n",
    "# print(type(x_test_ui8[1, 1, 1, 1]), x_test_ui8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.sum(y_test_f64))\n",
    "# temp = y_test_f64.shape\n",
    "# print(temp[0] * temp[1])\n",
    "\n",
    "y_test_f32 = y_test_f64.astype(np.float32)\n",
    "print(type(y_test_f32[1, 1]), y_test_f32.shape)\n",
    "y_test_ui8 = y_test_f32.astype(np.uint8)\n",
    "print(type(y_test_ui8[1, 1]), y_test_ui8.shape)\n",
    "y_test_bool = y_test_ui8.astype(np.bool_)\n",
    "print(type(y_test_bool[1, 1]), y_test_bool.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a specal case with perfect predictions.\n",
    "y_pred_f32 = np.random.random(y_test_bool.shape)*0.1\n",
    "y_pred_f32[y_test_bool] = y_pred_f32[y_test_bool]+0.9\n",
    "print(y_pred_f32.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty label samples\n",
    "indices_k3 = np.where(np.sum(y_test_bool, axis=1) > 0)[0]\n",
    "# Remove all samples that don't have exactly 3 labels.\n",
    "# indices_k3 = np.where(np.sum(y_test_bool, axis=1) == 3)[0]\n",
    "y_pred_f32 = y_pred_f32[indices_k3]\n",
    "y_test_f32 = y_test_f32[indices_k3]\n",
    "y_test_ui8 = y_test_ui8[indices_k3]\n",
    "y_test_bool = y_test_bool[indices_k3]\n",
    "print(type(y_pred_f32[1, 1]), y_pred_f32.shape)\n",
    "print(type(y_test_f32[1, 1]), y_test_f32.shape)\n",
    "print(type(y_test_ui8[1, 1]), y_test_ui8.shape)\n",
    "print(type(y_test_bool[1, 1]), y_test_bool.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply some label decision methods\n",
    "y_pred_bool_k = metrics.get_k_predictions(y_test_f32, y_pred_f32)\n",
    "y_pred_bool_3 = metrics.get_k_predictions(y_test_f32, y_pred_f32, k=3)\n",
    "y_pred_bool_tau = metrics.get_tau_predictions(y_test_f32, y_pred_f32)\n",
    "y_pred_bool_taus = metrics.get_tau_predictions(y_test_f32, y_pred_f32, tau=-1)\n",
    "print(type(y_pred_bool_k[1, 1]), y_pred_bool_k.shape)\n",
    "print(type(y_pred_bool_3[1, 1]), y_pred_bool_3.shape)\n",
    "print(type(y_pred_bool_tau[1, 1]), y_pred_bool_tau.shape)\n",
    "print(type(y_pred_bool_taus[1, 1]), y_pred_bool_taus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_pred_bool_k, axis=0)\n",
    "np.sum(y_pred_bool_taus, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.print_precision_recall_fscore(y_test_bool, y_pred_bool_k)\n",
    "print('')\n",
    "metrics.print_precision_recall_fscore(y_test_bool, y_pred_bool_3)\n",
    "print('')\n",
    "metrics.print_precision_recall_fscore(y_test_bool, y_pred_bool_tau)\n",
    "print('')\n",
    "metrics.print_precision_recall_fscore(y_test_bool, y_pred_bool_taus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see where we performed the worst.\n",
    "\n",
    "EPS = np.finfo(float).eps\n",
    "\n",
    "a = np.sum(y_pred_bool_k & y_test_bool, axis=1)\n",
    "b = np.sum(y_pred_bool_k, axis=1) + EPS\n",
    "c = np.sum(y_test_bool, axis=1) + EPS\n",
    "p_samp_k = a / b\n",
    "r_samp_k = a / c\n",
    "f1_samp_k = a / (b + c)\n",
    "\n",
    "bad_p_indices_k = np.argsort(p_samp_k)\n",
    "bad_r_indices_k = np.argsort(r_samp_k)\n",
    "bad_f1_indices_k = np.argsort(f1_samp_k)\n",
    "\n",
    "print(p_samp_k.shape, bad_p_indices_k[:5])\n",
    "print(r_samp_k.shape, bad_r_indices_k[:5])\n",
    "print(f1_samp_k.shape, bad_f1_indices_k[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 480\n",
    "print(y_test_bool[idx].astype(np.uint8))\n",
    "print(y_pred_f32[idx])\n",
    "print(y_pred_bool_k[idx].astype(np.uint8))\n",
    "print(y_pred_bool_tau[idx].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_test_example_index = np.argmax(np.sum(y_test_f32, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_test_example_index = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = x_test_ui8[biggest_test_example_index]\n",
    "img = valid_generator.load_image(biggest_test_example_index)[0]\n",
    "plt.imshow(img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "print(biggest_test_example_index)\n",
    "\n",
    "ranks = np.argsort(y_pred_f32[biggest_test_example_index])[::-1]\n",
    "biggest_test_example_dict = {\n",
    "    'y_test_f32': y_test_f32[biggest_test_example_index][ranks],\n",
    "    'y_pred_f32': y_pred_f32[biggest_test_example_index][ranks],\n",
    "    'y_pred_bool_k': y_pred_bool_k[biggest_test_example_index][ranks],\n",
    "    'y_pred_bool_tau': y_pred_bool_tau[biggest_test_example_index][ranks],\n",
    "}\n",
    "\n",
    "biggest_test_example_df = pd.DataFrame(biggest_test_example_dict, index=valid_generator.label_names[ranks])\n",
    "biggest_test_example_df.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sz = 10\n",
    "si = 0\n",
    "for idx in bad_f1_indices_k:\n",
    "# for idx in np.random.randint(len(y_test_ui8), size=5):\n",
    "    if np.sum(y_test_ui8[idx]) != 3:\n",
    "        continue\n",
    "    \n",
    "    si += 1    \n",
    "    img = valid_generator.load_image(idx)[0]\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "    test_indices = np.where(y_test_ui8[idx])[0]\n",
    "    pred_indices = np.argsort(y_pred_f32[idx])[::-1]\n",
    "    \n",
    "    ranks = []\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    labels = []\n",
    "    for i, pi in enumerate(pred_indices):\n",
    "        if i < len(test_indices) or pi in test_indices:\n",
    "            ranks.append(i+1)\n",
    "            y_test.append(y_test_ui8[idx][pi])\n",
    "            y_pred.append(y_pred_f32[idx][pi])\n",
    "            labels.append(valid_generator.label_names[pi])\n",
    "#             print(i+1, y_test_ui8[idx][pi], y_pred_f32[idx][pi], valid_generator.label_names[pi])\n",
    "        \n",
    "    test_example_dict = {\n",
    "        'y_test': y_test,\n",
    "        'y_pred': y_pred,\n",
    "        'label': labels\n",
    "    }\n",
    "    test_example_df = pd.DataFrame(test_example_dict, index=ranks)\n",
    "    print(idx)\n",
    "    print(test_example_df.to_latex())\n",
    "        \n",
    "    if si == sz:\n",
    "        break\n",
    "#     print(test_indices)\n",
    "#     print(y_test_ui8[idx][test_indices])\n",
    "#     print(valid_generator.label_names[test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sums_0 = np.sum(y_test_ui8, axis=0)\n",
    "test_sums_1 = np.sum(y_test_ui8, axis=1)\n",
    "\n",
    "idx = np.argmin(test_sums_1)\n",
    "img = valid_generator.load_image(idx)[0]\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(y_test_ui8.shape, idx, img.shape, img.min(), img.max())\n",
    "print(valid_generator.label_names[np.where(y_test_ui8[idx])[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_sort(y_test_bool, y_pred_bool, y_pred_float):\n",
    "    y_test_bool_sorted = np.empty(y_test_bool.shape, dtype=bool)\n",
    "    y_pred_bool_sorted = np.empty(y_pred_bool.shape, dtype=bool)\n",
    "    for i, preds in enumerate(y_pred_float):\n",
    "        sort_indices = np.argsort(preds)[::-1]\n",
    "        y_test_bool_sorted[i, :] = y_test_bool[i, sort_indices]\n",
    "        y_pred_bool_sorted[i, :] = y_pred_bool[i, sort_indices]\n",
    "    return y_test_bool_sorted, y_pred_bool_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_bool_sorted1, y_pred_k_bool_sorted1 = rank_sort(y_test_bool, y_pred_bool_k, y_pred_f32)\n",
    "y_test_bool_sorted1, y_pred_tau_bool_sorted1 = rank_sort(y_test_bool, y_pred_bool_tau, y_pred_f32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_precision_score(y_test_f32, y_pred_f32, average='micro'), 'micro')\n",
    "print(average_precision_score(y_test_f32, y_pred_f32, average='macro'), 'macro')\n",
    "print(label_ranking_average_precision_score(y_test_f32, y_pred_f32))\n",
    "print('prf k')\n",
    "print(average_precision_score(y_test_bool, y_pred_bool_k, average='micro'), 'micro')\n",
    "print(average_precision_score(y_test_bool, y_pred_bool_k, average='macro'), 'macro')\n",
    "print(average_precision_score(y_test_bool_sorted1, y_pred_k_bool_sorted1, average='micro'))\n",
    "print(average_precision_score(y_test_bool_sorted1, y_pred_k_bool_sorted1, average='macro'))\n",
    "print(precision_recall_fscore_support(y_test_bool, y_pred_bool_k, average='micro'), 'micro')\n",
    "print(precision_recall_fscore_support(y_test_bool, y_pred_bool_k, average='macro'), 'macro')\n",
    "print('prf tau')\n",
    "print(average_precision_score(y_test_bool, y_pred_bool_tau, average='micro'), 'micro')\n",
    "print(average_precision_score(y_test_bool, y_pred_bool_tau, average='macro'), 'macro')\n",
    "print(average_precision_score(y_test_bool_sorted1, y_pred_tau_bool_sorted1, average='micro'))\n",
    "print(average_precision_score(y_test_bool_sorted1, y_pred_tau_bool_sorted1, average='macro'))\n",
    "print(precision_recall_fscore_support(y_test_bool, y_pred_bool_tau, average='micro'), 'micro')\n",
    "print(precision_recall_fscore_support(y_test_bool, y_pred_bool_tau, average='macro'), 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_bool, y_pred_bool_tau, target_names=valid_generator.label_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test_f32, y_pred_bool_tau)\n",
    "prf1_dict = OrderedDict({\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'fscore': fscore,\n",
    "    'support': support\n",
    "})\n",
    "\n",
    "# ranks = np.argsort(y_pred_bool_tau_123[biggest_test_example_index])[::-1]\n",
    "# ranks = sorted(prf1_dict, key=itemgetter('support'), reverse=True)\n",
    "prf1_df = pd.DataFrame(prf1_dict, index=valid_generator.label_names)\n",
    "prf1_df.sort_values(by='support', ascending=False)\n",
    "# prf1_df.style"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
